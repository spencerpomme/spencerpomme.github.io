<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>品森</title>
  <subtitle>一人的呓语</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://spencerpomme.github.io/"/>
  <updated>2016-05-01T14:38:51.000Z</updated>
  <id>http://spencerpomme.github.io/</id>
  
  <author>
    <name>工常邵</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>用python写一个豆瓣小组的爬虫（一）</title>
    <link href="http://spencerpomme.github.io/2016/05/01/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%B1%86%E7%93%A3%E5%B0%8F%E7%BB%84%E7%9A%84%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://spencerpomme.github.io/2016/05/01/用python写一个豆瓣小组的爬虫（一）/</id>
    <published>2016-05-01T14:34:36.000Z</published>
    <updated>2016-05-01T14:38:51.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;用python写一个豆瓣小组的爬虫（一）&quot;&gt;&lt;a href=&quot;#用python写一个豆瓣小组的爬虫（一）&quot; class=&quot;headerlink&quot; title=&quot;用python写一个豆瓣小组的爬虫（一）&quot;&gt;&lt;/a&gt;用python写一个豆瓣小组的爬虫（一）&lt;/h2&gt;&lt;p&gt;这是一篇夹杂着大量私货的“技术贴”。&lt;/p&gt;
&lt;p&gt;豆瓣是一个神奇的网站。我大概是在07年的时候知道有豆瓣这个网站，然后在高考之后有一段时间整天泡在上边，每看完一部电影就上去标记为“看过”，写个短评，乐此不疲。豆瓣fm也是一个我非常喜欢的功能，我曾经最喜欢的事情之一就是一边听着私人电台，一边在阿尔法城逛来逛去（后来阿尔法城关掉了）。再写下去就要写成豆瓣的软文了，哈。不过确实想说，作为最早的一批90，豆瓣在当时有点像是早几年前的知乎，也像是40年代的魔兽世界，是一个令人怀念的小社区。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.douban.com/group/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;豆瓣小组&lt;/a&gt;不得不说是豆瓣比较成功的一个子产品，当时我初次接触的时候就觉得，“比百度贴吧不知道高到哪里去了”。也许是建筑学的教育背景让我培养了一丝的审美观，也可能是觉得豆瓣小组里的广告虽然也有但远没有那么&lt;strong&gt;人命关天&lt;/strong&gt;，总之，看着舒服。这不算是对豆瓣的夸奖，因为事实上仅仅就产品本身将豆瓣小组与百度贴吧相比较，就足够令人生疑我是不是在黑豆瓣了。不是的，我只是在客观地表达作为一个用户的用户体验而已。&lt;strong&gt;不过需要澄清的是&lt;/strong&gt;，我对于百度的不齿只局限于其决策层的所作所为（或者是不作为？），至于所有勤勤恳恳地码着代码的工程师、产品经理和设计师等等，谁不是在养家糊口呢？&lt;/p&gt;
&lt;p&gt;豆瓣小组确实也不是尽善尽美。豆瓣的数据获取实在不甚方便。之前写地址解析的时候调用过百度的API，用起来十分顺手和方便（毕竟是技术实力雄厚的公司），但是&lt;strong&gt;反观豆瓣的API调用，处处受限，而豆瓣小组干脆则是没有API的&lt;/strong&gt;。在网络上搜集数据，一般来说有API最好，实在没有办法才写爬虫，毕竟前者多快好省而后者不但麻烦还有一点ethical controversy，搞不好容易吃上官司。（当然我这样子的小白就算是写爬虫也不至于惊动到这一步吧，😓）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;好吧反正我就是要写一个爬虫，把豆瓣小组中我感兴趣的话题都收入囊中&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;以下内容假定读者了解python语法（comfortable about write codes longer than 100 lines）并了解python的包管理，具有对命令行的初步认识。此外，对HTML有个大体的认识会更有助于在阅读后举一反三。&lt;strong&gt;如果你已经比较了解爬虫，这篇博客可能不适合你，&lt;/strong&gt;这篇文章面向的读者是初学者。&lt;strong&gt;但是&lt;/strong&gt;, 就算你都不懂，这篇文章还有一个重要的目标读者群体是&lt;strong&gt;对数据感兴趣的城市规划师&lt;/strong&gt;，这部分同学可以大概了解一下思路，然后去我的github把代码改一改直接就能做关于豆瓣用户的地域空间分布／勾搭od分析／&lt;strong&gt;男(女)p友走遍全国&lt;/strong&gt;，等等这类奇葩的分析了，说不定你的python代码还能&lt;a href=&quot;https://www.zhihu.com/question/30537262&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;写1万行&lt;/a&gt;呢。&lt;/p&gt;
&lt;p&gt;吐槽完毕，下边开始务实。&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&quot;一、前期准备&quot;&gt;&lt;a href=&quot;#一、前期准备&quot; class=&quot;headerlink&quot; title=&quot;一、前期准备&quot;&gt;&lt;/a&gt;一、前期准备&lt;/h4&gt;&lt;p&gt;确认你有以下第三方库（我用python3）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://docs.python-requests.org/en/master/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;requests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.crummy.com/software/BeautifulSoup/bs4/doc/#&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;beautiful soup 4&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ pip install requests&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ pip install beautifulsoup4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;本文中将会用到这两个第三方库。&lt;/p&gt;
&lt;h4 id=&quot;二、解释本文爬虫的工作原理&quot;&gt;&lt;a href=&quot;#二、解释本文爬虫的工作原理&quot; class=&quot;headerlink&quot; title=&quot;二、解释本文爬虫的工作原理&quot;&gt;&lt;/a&gt;二、解释本文爬虫的工作原理&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;访问网页，把整个页面的源代码抓取下来，分析页面源代码，抽取想要的信息，并存下来。即：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;获取网页&lt;/li&gt;
&lt;li&gt;抽取信息&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在这里，我用requests做抓取这一步，然后用beautifulsoup做分析这一步。虽然自带的urllib挺好的，但是python2和python3的urllib无法兼容，所以采用一个更不容易出问题的。这里的问题是指人犯错，而不是库有bug😂，蛤蛤。&lt;/p&gt;
&lt;p&gt;至于beautifulsoup，我觉得用着很是省心。除了因为暂时没有必(neng)要(li)自己造轮子外，用纯正则表达式来分析HTML的话，差不多可以拍一部电影叫做&lt;em&gt;Fifty shades of rex[^1]&lt;/em&gt;了，但我没有这样的爱好，真的。不过话又说回来，五十度灰的男女主角身材真是好，通过强烈刺激观众大脑的某一区域，似乎成功地阻碍了另一部分区域正常发挥作用，这解释了为什么这部电影的豆瓣评分会远远高于我的预想。这外貌协会（又玛丽苏）的世界。&lt;/p&gt;
&lt;p&gt;所以明白了原理，&lt;strong&gt;let’s just shut the f*ck up and write some codes.&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;三、首先，你要有一个…&quot;&gt;&lt;a href=&quot;#三、首先，你要有一个…&quot; class=&quot;headerlink&quot; title=&quot;三、首先，你要有一个…&quot;&gt;&lt;/a&gt;三、首先，你要有一个…&lt;/h4&gt;&lt;p&gt;这个节标题没有任何恶意🐶&lt;/p&gt;
&lt;p&gt;真的，我是指你要有一个&lt;del&gt;女朋友&lt;/del&gt;目标小组。比如这个：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/groupiwgf.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;蛤蛤&lt;/p&gt;
&lt;p&gt;下边让我们一步一步来：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#! python3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# code list part 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; requests&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; bs4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# url: the target group&#39;s url&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;url = &lt;span class=&quot;string&quot;&gt;&quot;https://www.douban.com/group/needGF/discussion?start=0&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# now use requests to get the page&#39;s html file&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;html = requests.get(url)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(html)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# to be continued...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;也许你是在idle里写的这几行代码，也许是写在记事本里，总之运行它。你会发现整个网页的源码都print出来了。第一步完成啦，excited.&lt;/p&gt;
&lt;h4 id=&quot;三、使用beautiful-soup解析网页&quot;&gt;&lt;a href=&quot;#三、使用beautiful-soup解析网页&quot; class=&quot;headerlink&quot; title=&quot;三、使用beautiful soup解析网页&quot;&gt;&lt;/a&gt;三、使用beautiful soup解析网页&lt;/h4&gt;&lt;p&gt;接着就是抽取想要的信息。本文只想做一步，就是获取帖子的&lt;strong&gt;标题&lt;/strong&gt;，&lt;strong&gt;发帖人&lt;/strong&gt;，&lt;strong&gt;回复数&lt;/strong&gt;，&lt;strong&gt;最后回复时间&lt;/strong&gt;以及&lt;strong&gt;发帖人主页链接&lt;/strong&gt;和&lt;strong&gt;帖子链接&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;然而为什么需要链接呢？依我自己的经验，人有的时候真的会抑制不住好奇心去看看发了&lt;strong&gt;“叔帅还霸道，有钱”&lt;/strong&gt;这样子的帖子是何方高富帅，也会想要去围观一下&lt;strong&gt;“楼主女，懂的来”&lt;/strong&gt;这样的帖子，检验一下自己&lt;del&gt;懂不懂&lt;/del&gt;革命意志是否坚定。开玩笑啦，其实保留链接的目的是为了做更为复杂的爬虫，即让爬虫可以继续顺着链接爬下去，这样才有可能得出所有用户的关系图[^2]。&lt;/p&gt;
&lt;p&gt;那么让我们来看看怎么做：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# adjacent to code list part 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# this is code list part 2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;soup = bs4.BeautifulSoup(html.text, &lt;span class=&quot;string&quot;&gt;&quot;lxml&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# the data are stored in a &amp;lt;table&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;table = soup.findAll(&lt;span class=&quot;string&quot;&gt;&quot;table&quot;&lt;/span&gt;, &amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;class&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;olt&quot;&lt;/span&gt;&amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# to be continued...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这一步，我们把网页源代码转化成了一个bs4.BeautifulSoup object，这样就可以进行后续的信息抽取了。具体的实现方式不是唯一的，事实上我个人感觉bs4这个库可以有很多方式做到同一件事，教条地说这并不很pythonic。&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# adjacent to code list part 2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# this is code list part 3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# rows are rows in the table&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;rows = list(table)[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;].findAll(&lt;span class=&quot;string&quot;&gt;&quot;tr&quot;&lt;/span&gt;, &amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;class&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;&amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; row &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; rows:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    title = row.find(&lt;span class=&quot;string&quot;&gt;&quot;td&quot;&lt;/span&gt;, &amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;class&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;title&quot;&lt;/span&gt;&amp;#125;).a.attrs[&lt;span class=&quot;string&quot;&gt;&quot;title&quot;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    title_url = row.find(&lt;span class=&quot;string&quot;&gt;&quot;td&quot;&lt;/span&gt;, &amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;class&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;title&quot;&lt;/span&gt;&amp;#125;).a.attrs[&lt;span class=&quot;string&quot;&gt;&quot;href&quot;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    author = row.find(&lt;span class=&quot;string&quot;&gt;&quot;td&quot;&lt;/span&gt;, &amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;nowrap&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;nowrap&quot;&lt;/span&gt;&amp;#125;).a.text&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    author_url = row.find(&lt;span class=&quot;string&quot;&gt;&quot;td&quot;&lt;/span&gt;, &amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;nowrap&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;nowrap&quot;&lt;/span&gt;&amp;#125;).a.attrs[&lt;span class=&quot;string&quot;&gt;&quot;href&quot;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    follow = row.find(&lt;span class=&quot;keyword&quot;&gt;lambda&lt;/span&gt; tag: len(tag.attrs)==&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; tag.name==&lt;span class=&quot;string&quot;&gt;&quot;td&quot;&lt;/span&gt;).text&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    time = row.find(&lt;span class=&quot;string&quot;&gt;&quot;td&quot;&lt;/span&gt;, &amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;nowrap&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;nowrap&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;class&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;time&quot;&lt;/span&gt;&amp;#125;).text&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    print(title, title_url)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    print(author, author_url)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    print(follow)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    print(time)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# let&#39;s call it a day&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过这样子，我们就得到了一页当中的所有帖子的各项信息。如果有任何不懂，参看beautifulsoup的文档。&lt;/p&gt;
&lt;h4 id=&quot;四、距离真正可以使用还差几步&quot;&gt;&lt;a href=&quot;#四、距离真正可以使用还差几步&quot; class=&quot;headerlink&quot; title=&quot;四、距离真正可以使用还差几步&quot;&gt;&lt;/a&gt;四、距离真正可以使用还差几步&lt;/h4&gt;&lt;p&gt;仅仅print出来是不可以接受的，因为一个真正的爬虫还至少需要能够把数据存起来。而且，之前的代码只是爬取了一页，我们还需要在外边套上一层循环。最后，考虑到限制，我们还需要使用代理，或者设置sleep time来慢慢爬，防止被服务器封印掉IP。&lt;/p&gt;
&lt;p&gt;但是我今天累了，劳动节要早点睡。晚安。&lt;/p&gt;
&lt;p&gt;别打我，我其实也没有写完呢。代码见我的GITHUB，或者直接戳这里：&lt;a href=&quot;https://github.com/spencerpomme/screwpie&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;screwpie&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[^1]: rex is abbreviation for regular expression&lt;br&gt;[^2]: graph here is a algorithmic concept, a kind of data structure&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;用python写一个豆瓣小组的爬虫（一）&quot;&gt;&lt;a href=&quot;#用python写一个豆瓣小组的爬虫（一）&quot; class=&quot;headerlink&quot; title=&quot;用python写一个豆瓣小组的爬虫（一）&quot;&gt;&lt;/a&gt;用python写一个豆瓣小组的爬虫（一）&lt;/h2&gt;&lt;
    
    </summary>
    
      <category term="CS" scheme="http://spencerpomme.github.io/categories/CS/"/>
    
    
      <category term="爬虫" scheme="http://spencerpomme.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>Wordlist Story 1</title>
    <link href="http://spencerpomme.github.io/2016/04/20/Wordlist%20Story%201/"/>
    <id>http://spencerpomme.github.io/2016/04/20/Wordlist Story 1/</id>
    <published>2016-04-20T12:39:14.000Z</published>
    <updated>2016-04-20T13:01:08.000Z</updated>
    
    <content type="html">&lt;p&gt;####Chapter one (not finished)&lt;br&gt;The &lt;strong&gt;underground&lt;/strong&gt; world&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Everything changed the day my foster parents took me out of that &lt;strong&gt;frigid&lt;/strong&gt; orphanage, the place was much more a place for &lt;strong&gt;contrition&lt;/strong&gt; than parentless children.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;strong&gt;unidimensional&lt;/strong&gt; world is not lifeless. If I’m being &lt;strong&gt;retentive&lt;/strong&gt; and still have the mental &lt;strong&gt;agility&lt;/strong&gt;, it could be a long story that may &lt;strong&gt;overwhelm&lt;/strong&gt; you with the details. However, I have such an &lt;strong&gt;infamous&lt;/strong&gt; memory that I may &lt;strong&gt;jeopardize&lt;/strong&gt; the accuracy of the story if I &lt;strong&gt;unscrupulous&lt;/strong&gt;ly fabricate the parts those seem blurred to me. In order to be &lt;strong&gt;dutiful&lt;/strong&gt; storyteller, it better be terse. Don’t worry, it’s not going to be an &lt;strong&gt;insipid&lt;/strong&gt; one though.&lt;/p&gt;
&lt;p&gt;It was about seventy years ago that I got &lt;strong&gt;adopt&lt;/strong&gt;ed by a couple who are both scientists. I used to be a &lt;strong&gt;flabby&lt;/strong&gt; boy back then and as a result got beaten up a lot by bullies in the orphanage, the &lt;strong&gt;Clemency&lt;/strong&gt; of Jesus state orphanage. This experience may be the cause of the &lt;strong&gt;fickleness&lt;/strong&gt; in my personality since I always felt my future was &lt;strong&gt;chancy&lt;/strong&gt; and &lt;strong&gt;devoid&lt;/strong&gt; of hope. Everything changed the day my step parents took me out of that &lt;strong&gt;frigid&lt;/strong&gt; orphanage, the place was much more a place for &lt;strong&gt;contrition&lt;/strong&gt; than parentless children.&lt;/p&gt;
&lt;p&gt;My foster father was a &lt;strong&gt;prestigious&lt;/strong&gt; physicist and Marry, my foster mother, was also a physicist as well as a profound engineer. For a long time, we lived a &lt;strong&gt;spartan&lt;/strong&gt; life in a villa located on the &lt;strong&gt;ridge&lt;/strong&gt; of a dead volcano that its &lt;strong&gt;crater&lt;/strong&gt; is within a hundred yard from our front door. It’s &lt;strong&gt;nonthreatening&lt;/strong&gt;, of course. The &lt;strong&gt;alienation&lt;/strong&gt; from mainstream society could be a &lt;strong&gt;boon&lt;/strong&gt; to someone &lt;strong&gt;agoraphobic&lt;/strong&gt;, but not to an ten-year-old boy. Very soon, my &lt;strong&gt;congenital&lt;/strong&gt; &lt;strong&gt;proclivity&lt;/strong&gt; for exploration was &lt;strong&gt;galvanize&lt;/strong&gt;d. One &lt;strong&gt;sultry&lt;/strong&gt; afternoon of August 18th 1946, I had a conversation with my father which lead to the start of our story.&lt;/p&gt;
&lt;p&gt;“Papa, are we &lt;strong&gt;derelict&lt;/strong&gt;s of modern society?” I asked in a &lt;strong&gt;disgruntled&lt;/strong&gt; voice.”&lt;/p&gt;
&lt;p&gt;“Oh my little Pinsent, where does this &lt;strong&gt;platitudinous&lt;/strong&gt; remark come from?”, my father seems a little surprised as well as amused. He untied the &lt;strong&gt;buckle&lt;/strong&gt; of a machine which was used to &lt;strong&gt;irradiate&lt;/strong&gt; some ore and the experiment stopped. As he turned face to me the glow of the ore ceased in an &lt;strong&gt;anticlimactic&lt;/strong&gt; way.&lt;/p&gt;
&lt;p&gt;“Is it because of &lt;strong&gt;defamation&lt;/strong&gt;s those &lt;strong&gt;vitriolic&lt;/strong&gt; people spread about you and mama or they trying to &lt;strong&gt;encumber&lt;/strong&gt; your work?” I jump up to papa’s desk, sitting &lt;strong&gt;abreast&lt;/strong&gt; that &lt;strong&gt;elaborate&lt;/strong&gt; machine. “Mama told me that they even &lt;strong&gt;excise&lt;/strong&gt;d you from the academy, it’s &lt;strong&gt;implausible&lt;/strong&gt;!” I murmured.&lt;/p&gt;
&lt;p&gt;“Son, someday you may realize that being &lt;strong&gt;supplant&lt;/strong&gt;ed is not necessarily a &lt;strong&gt;punishment&lt;/strong&gt; but to gain &lt;strong&gt;opulent&lt;/strong&gt; amount of free time. As long as one belongs to a certain organization he has to show &lt;strong&gt;conformity&lt;/strong&gt;, otherwise you might be considered a haughty and immature person.” My father responded in a &lt;strong&gt;sedate&lt;/strong&gt; voice, looked me in the eye. It was like he was trying to &lt;strong&gt;engrave&lt;/strong&gt; this into my head, but then he smiled, with understanding of his son’s boredom, “Do you want to know what this &lt;strong&gt;outmoded&lt;/strong&gt; machine is?” &lt;/p&gt;
&lt;p&gt;“What? Outmoded… Then what is it, papa? &lt;em&gt;Who&lt;/em&gt; made it?” I couldn’t move away my eyes from that &lt;strong&gt;dumbbell-like&lt;/strong&gt; machine, which seems &lt;strong&gt;unworldly&lt;/strong&gt; that not likely to be created by man. My father was a physicist with &lt;strong&gt;talent&lt;/strong&gt; and &lt;strong&gt;towering&lt;/strong&gt; acadamical achievements, this is one thing. But this machine? It’s just so &lt;strong&gt;deviant&lt;/strong&gt; for a scientific equipment.&lt;/p&gt;
&lt;p&gt;“I don’t want to &lt;strong&gt;disillusion&lt;/strong&gt; you, my son. But it was just a gift from an &lt;strong&gt;anterior&lt;/strong&gt; friend. That friend of mine tried to &lt;strong&gt;provoke&lt;/strong&gt; me by sending a &lt;em&gt;thing&lt;/em&gt; that nobody knows what it is and where it comes from.” He frowned, “Last several years I was haunted by &lt;strong&gt;self-doubt&lt;/strong&gt; that I may never be able to reveal its &lt;strong&gt;inherent&lt;/strong&gt; nature. Of course I have some &lt;strong&gt;hypotheses&lt;/strong&gt;, but all of them lack of &lt;strong&gt;corroboration&lt;/strong&gt;.”&lt;/p&gt;
&lt;p&gt;As far I as can remember, my father never tended to &lt;strong&gt;deplore&lt;/strong&gt; the &lt;strong&gt;comic&lt;/strong&gt; act of his &lt;strong&gt;immature&lt;/strong&gt; friend, in &lt;strong&gt;inverse&lt;/strong&gt; he was so &lt;strong&gt;possessed&lt;/strong&gt; of digging out its secret which seemed &lt;strong&gt;undecipherable&lt;/strong&gt; as if he had a &lt;strong&gt;rival&lt;/strong&gt; to compete with. He had never been such a &lt;strong&gt;zealot&lt;/strong&gt;, but for some time even my mother thought he’s a “strange machine &lt;strong&gt;fanatic&lt;/strong&gt;“. My mother may preserved an appearance of &lt;strong&gt;nonchalance&lt;/strong&gt;, but her &lt;strong&gt;insight&lt;/strong&gt; far &lt;strong&gt;transcend&lt;/strong&gt;s my fahter’s. With a &lt;strong&gt;cursory&lt;/strong&gt; glance she drawed a conclusion that this machine must be alien.&lt;/p&gt;
&lt;p&gt;“How can you be so sure,” My father asked on dinner table later that day, “You need to do &lt;strong&gt;repetitive&lt;/strong&gt; &lt;strong&gt;reaffirmations&lt;/strong&gt; before &lt;strong&gt;repudiating&lt;/strong&gt; my &lt;strong&gt;hypothesis&lt;/strong&gt;.”&lt;/p&gt;
&lt;p&gt;(To be continued…)&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;####Chapter one (not finished)&lt;br&gt;The &lt;strong&gt;underground&lt;/strong&gt; world&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Everything changed the day my foster parents
    
    </summary>
    
      <category term="英语" scheme="http://spencerpomme.github.io/categories/%E8%8B%B1%E8%AF%AD/"/>
    
    
      <category term="GRE" scheme="http://spencerpomme.github.io/tags/GRE/"/>
    
  </entry>
  
  <entry>
    <title>c多文件编译的命令行方法（gcc）</title>
    <link href="http://spencerpomme.github.io/2016/04/17/c%E5%A4%9A%E6%96%87%E4%BB%B6%E7%BC%96%E8%AF%91%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%96%B9%E6%B3%95%EF%BC%88gcc%EF%BC%89/"/>
    <id>http://spencerpomme.github.io/2016/04/17/c多文件编译的命令行方法（gcc）/</id>
    <published>2016-04-17T07:27:07.000Z</published>
    <updated>2016-04-18T06:34:43.000Z</updated>
    
    <content type="html">&lt;p&gt;之前在学习数据结构的时候（现在还没有学完orz）发现，其实学习到后边的树、图之类的数据结构的时候，经常会用到stack和queue这两个更为基础的数据结构，需要经常性地包含它们的头文件。一直以来都直接用IDE来做这个事情，直到有一天觉得每次做题都要新建一个工程然后添加文件很麻烦，就决定把常用数据结构的.c和.h放在一个文件夹里，题目做完了就把problem.c放到这个文件夹里用命令行编译一下就得了。&lt;/p&gt;
&lt;p&gt;其实挺起来好像还是挺麻烦的，不过就当作是增添一项新经验也好。具体做法如下：（以stack.c和stack.h为例）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把需要一起变一的文件都放入一个directory里边去&lt;/li&gt;
&lt;li&gt;&lt;p&gt;cmd/powershell(windows平台)进行如下操作：&lt;/p&gt;
&lt;p&gt; &lt;code&gt;&amp;gt;&amp;gt;&amp;gt; gcc -std=c99 stack.c problem.c -o main&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样在文件夹里就会出现一个名为main.exe的文件了。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;之前在学习数据结构的时候（现在还没有学完orz）发现，其实学习到后边的树、图之类的数据结构的时候，经常会用到stack和queue这两个更为基础的数据结构，需要经常性地包含它们的头文件。一直以来都直接用IDE来做这个事情，直到有一天觉得每次做题都要新建一个工程然后添加文件很
    
    </summary>
    
      <category term="CS" scheme="http://spencerpomme.github.io/categories/CS/"/>
    
    
      <category term="gcc" scheme="http://spencerpomme.github.io/tags/gcc/"/>
    
  </entry>
  
</feed>
